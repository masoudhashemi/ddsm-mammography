{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 18:11:44.974855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "from torch.utils.data import Subset\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "from datasets import load_metric\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = pickle.load(open('images_10_3_normal.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11177, 100, 100, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the classes in a balanced way\n",
    "def train_test_split(labels, split_ratio=0.8):\n",
    "    # Calculate the class frequencies\n",
    "    class_counts = Counter(labels)\n",
    "\n",
    "    # Calculate the number of samples in the train and test sets\n",
    "    num_samples = len(labels)\n",
    "    split_ratio = split_ratio \n",
    "    num_train_samples = int(num_samples * split_ratio)\n",
    "    num_test_samples = num_samples - num_train_samples\n",
    "\n",
    "    # Create a list of tuples, where each tuple contains the class label and the corresponding indices of the samples\n",
    "    label_indices = [(label, np.where(labels == label)[0]) for label in class_counts.keys()]\n",
    "\n",
    "    # Initialize the train and test sets\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    # Loop over the list of tuples\n",
    "    for label, indices in label_indices:\n",
    "        # Calculate the number of samples for this class\n",
    "        num_samples = len(indices)\n",
    "\n",
    "        # Calculate the number of samples in the train and test sets for this class\n",
    "        num_train_samples = int(num_samples * split_ratio)\n",
    "        num_test_samples = num_samples - num_train_samples\n",
    "\n",
    "        # Select the train and test indices for this class\n",
    "        train_indices += random.sample(list(indices), num_train_samples)\n",
    "        test_indices += [i for i in indices if i not in train_indices]\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if they are balanced?\n",
    "\n",
    "train_indices, test_indices = train_test_split(labels, split_ratio=0.4)\n",
    "\n",
    "np.unique(labels[train_indices], return_counts=True), np.unique(labels[test_indices], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(labels, return_counts=False))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'google/vit-base-patch16-224'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {}\n",
    "id2label = {}\n",
    "\n",
    "for i, class_name in enumerate(range(num_classes)):\n",
    "    label2id[class_name] = str(i)\n",
    "    id2label[str(i)] = class_name\n",
    "    \n",
    "id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationCollator:\n",
    "    def __init__(self, feature_extractor):\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        encodings = self.feature_extractor([x[0] for x in batch], return_tensors='pt')\n",
    "        encodings['labels'] = torch.tensor([x[1] for x in batch], dtype=torch.long)\n",
    "        return encodings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDSM(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = Image.fromarray(self.images[idx]), self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders\n",
    "\n",
    "train_ds = DDSM(images[train_indices], labels[train_indices])\n",
    "val_ds = DDSM(images[test_indices], labels[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = ImageClassificationCollator(feature_extractor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, collate_fn=collator, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=8, collate_fn=collator)\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=len(label2id),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(iter(train_loader))\n",
    "model(**d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, lr: float = 2e-5, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters('lr', *list(kwargs))\n",
    "        self.model = model\n",
    "        self.forward = self.model.forward\n",
    "        self.val_acc = Accuracy()\n",
    "        self.train_acc= Accuracy()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(**batch)\n",
    "        self.log(f\"train_loss\", outputs.loss)\n",
    "        acc1 = self.train_acc(outputs.logits.argmax(1), batch['labels'])\n",
    "        self.log(f\"train_acc\", acc1, prog_bar=True)\n",
    "        return outputs.loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(**batch)\n",
    "        self.log(f\"val_loss\", outputs.loss)\n",
    "        acc = self.val_acc(outputs.logits.argmax(1), batch['labels'])\n",
    "        self.log(f\"val_acc\", acc, prog_bar=True)\n",
    "        return outputs.loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr,weight_decay=0.0025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(42)\n",
    "classifier = Classifier(model, lr=2e-5)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='./vit_content/trainmebby',\n",
    "    filename='ViT-{epoch:02d}-{val_loss:.2f}',\n",
    ")\n",
    "trainer = pl.Trainer(callbacks=[checkpoint_callback], max_epochs=3, gpus=1, precision=16)\n",
    "trainer.fit(classifier, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "20f972b5ec01afc6342c701ce71b35de9888327d446d177ef66e3c862529bc3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
